{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:27:38.277980603Z",
     "start_time": "2024-02-15T14:27:36.947666106Z"
    }
   },
   "outputs": [],
   "source": [
    "from wandb.sdk import wandb_config\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "from model.train import train\n",
    "from utils.configs import *\n",
    "from data.CommentaryDataloader import get_commentary_dataloader\n",
    "from data.CommentaryDataset import CommentaryDataset\n",
    "from model.predict import Predictor\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_configs_from_wandb_config(wandb_config: WandbConfig, is_real_wandb: bool):\n",
    "    if wandb_config['model_name'] not in ['model', 'model_residual_encoder']:\n",
    "        raise ValueError('Model should be model or model_residual_encoder')\n",
    "    \n",
    "    shared_config: SharedConfig = {\n",
    "        'context_length': wandb_config['context_length'],\n",
    "        'sentencepiece_path': f\"./artifacts/sp{wandb_config['sp_vocab']}.model\",\n",
    "        'bos_id': 0, # will be initialized later\n",
    "        'eos_id': 1, # will be initialized later\n",
    "        'pad_id': 2, # will be initialized later\n",
    "        'vocab_size': 0 # will be initialized later\n",
    "    }\n",
    "    \n",
    "    train_data_config: DataConfig = {\n",
    "        'batch_size': wandb_config['batch_size'],\n",
    "        'split': 'train',\n",
    "        'data_path': './processed_data',\n",
    "        'past_boards': wandb_config['past_boards'],\n",
    "        'stride_big_sequences': wandb_config['stride_big_sequences'],\n",
    "        'in_memory': False,\n",
    "        'dl_shuffle': False,\n",
    "        'dl_samples': wandb_config['samples_per_train_epoch'],\n",
    "        'dl_num_workers': 2,\n",
    "    }\n",
    "    \n",
    "    valid_data_config: DataConfig = {\n",
    "        'batch_size': wandb_config['batch_size'],\n",
    "        'split': 'valid',\n",
    "        'data_path': './processed_data',\n",
    "        'past_boards': wandb_config['past_boards'],\n",
    "        'stride_big_sequences': wandb_config['stride_big_sequences'],\n",
    "        'in_memory': True,\n",
    "        'dl_shuffle': True,\n",
    "        'dl_samples': None,\n",
    "        'dl_num_workers': 1,\n",
    "    }\n",
    "    \n",
    "    test_data_config: DataConfig = {\n",
    "        'batch_size': wandb_config['batch_size'],\n",
    "        'split': 'valid',\n",
    "        'data_path': './processed_data',\n",
    "        'past_boards': wandb_config['past_boards'],\n",
    "        'stride_big_sequences': wandb_config['stride_big_sequences'],\n",
    "        'in_memory': False,\n",
    "        'dl_shuffle': False,\n",
    "        'dl_samples': None,\n",
    "        'dl_num_workers': 0,\n",
    "    }\n",
    "    \n",
    "    model_config: ModelConfig = {\n",
    "        'name': Models.MODEL_RESIDUAL_ENCODER,\n",
    "        'board_embedding_size': wandb_config['board_embedding_size'],\n",
    "        'text_embedding_size': wandb_config['text_embedding_size'],\n",
    "        'conv_modules_count': wandb_config['conv_modules_count'],\n",
    "        'transformer_blocks': wandb_config['transformer_blocks'],\n",
    "        'board_intermediary_channels': wandb_config['board_intermediary_channels'],\n",
    "        'board_in_channels': CommentaryDataset.get_board_channels(train_data_config),\n",
    "        'board_height': 8,\n",
    "        'board_width': 8,\n",
    "        'board_depth': wandb_config['board_embedding_size'],\n",
    "        'ff_inner_channels': wandb_config['ff_inner_channels'],\n",
    "        'num_heads': wandb_config['num_heads']\n",
    "    }\n",
    "    \n",
    "    if wandb_config['optimizer'] not in ['adam', 'sgd']:\n",
    "        raise ValueError('Optimizer value invalid')\n",
    "    \n",
    "    train_config: TrainConfig = {\n",
    "        'lr': wandb_config['lr'],\n",
    "        'with_wandb': is_real_wandb,\n",
    "        'num_epochs': wandb_config['num_epochs'],\n",
    "        'predict_sentences': wandb_config['predict_sentences'],\n",
    "        'optimizer': Optimizers.ADAM if wandb_config['optimizer'] == 'adam' else Optimizers.SGD\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'shared_config': shared_config,\n",
    "        'train_config': train_config,\n",
    "        'model_config': model_config,\n",
    "        'test_data_config': test_data_config,\n",
    "        'train_data_config': train_data_config,\n",
    "        'valid_data_config': valid_data_config\n",
    "    }     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:27:38.282930002Z",
     "start_time": "2024-02-15T14:27:38.282243186Z"
    }
   },
   "id": "823d055de6f736e8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# local_wandb_config: WandbConfig = {\n",
    "#     'text_embedding_size': 64,\n",
    "#     'conv_modules_count': 6,\n",
    "#     'transformer_blocks': 6,\n",
    "#     'board_intermediary_channels': 64,\n",
    "#     'board_embedding_size': 64,\n",
    "#     'ff_inner_channels': 64,\n",
    "#     'num_heads': 4,\n",
    "#     'lr': 0.01,\n",
    "#     'optimizer': 'sgd',\n",
    "#     'num_epochs': 200,\n",
    "#     'context_length': 256,\n",
    "#     'sp_vocab': 800,\n",
    "#     'batch_size': 64,\n",
    "#     'past_boards': 1,\n",
    "#     'stride_big_sequences': 64,\n",
    "#     'samples_per_train_epoch': 100000,\n",
    "#     'predict_sentences': 4\n",
    "# }\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"val_loss\"},\n",
    "    \"parameters\": {\n",
    "        'model_name': {\"values\": ['model_residual_encoder', 'model'] },\n",
    "        'text_embedding_size': {\"distribution\": \"q_log_uniform_values\", \"min\": 64, \"max\": 256, \"q\": 64},\n",
    "        'conv_modules_count': {\"values\": [1, 2, 3, 4]},\n",
    "        'transformer_blocks': {\"values\": [1, 2, 3, 4]},\n",
    "        'board_intermediary_channels': {\"distribution\": \"q_log_uniform_values\", \"min\": 64, \"max\": 512, \"q\": 64},\n",
    "        'board_embedding_size': {\"distribution\": \"q_log_uniform_values\", \"min\": 64, \"max\": 256, \"q\": 64},\n",
    "        'ff_inner_channels': {\"distribution\": \"q_log_uniform_values\", \"min\": 64, \"max\": 512, \"q\": 64},\n",
    "        'num_heads': {\"distribution\": \"q_log_uniform_values\", \"min\": 4, \"max\": 8, \"q\": 4},\n",
    "        'lr': {\"distribution\": \"uniform\", \"max\": 0.4, \"min\": 0},\n",
    "        'optimizer': {\"values\": ['sgd', 'adam']},\n",
    "        'num_epochs': {\"values\": [2, 3, 4]},\n",
    "        'context_length': {\"distribution\": \"q_log_uniform_values\", \"min\": 64, \"max\": 512, \"q\": 64},\n",
    "        'sp_vocab': {\"values\": [700, 800, 900]},\n",
    "        'batch_size': {\"distribution\": \"q_log_uniform_values\", \"min\": 64, \"max\": 256, \"q\": 64},\n",
    "        'past_boards': {\"values\": [0, 1, 2]},\n",
    "        'stride_big_sequences': {\"values\": [256, 512]},\n",
    "        'samples_per_train_epoch': {\"values\": [10000, 100000]},\n",
    "        'predict_sentences': {\"values\": [10]}\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:27:38.287040373Z",
     "start_time": "2024-02-15T14:27:38.283516623Z"
    }
   },
   "id": "f6b9264bb5d3bfc7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run(): \n",
    "    with wandb.init(project=\"thesis\"):\n",
    "        configs = get_configs_from_wandb_config(wandb.config, True)\n",
    "        train(\n",
    "            model_config=configs['model_config'],\n",
    "            train_config=configs['train_config'],\n",
    "            shared_config=configs['shared_config'],\n",
    "            train_dl=get_commentary_dataloader(configs['train_data_config'], configs['shared_config'])[0],\n",
    "            val_dl=get_commentary_dataloader(configs['valid_data_config'], configs['shared_config'])[0],\n",
    "            test_ds=CommentaryDataset(configs['test_data_config'], configs['shared_config']),\n",
    "            predictor=Predictor(configs['shared_config'])\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:27:38.289949881Z",
     "start_time": "2024-02-15T14:27:38.288871787Z"
    }
   },
   "id": "82d09924b37aa7fb",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: pj49gpx4\n",
      "Sweep URL: https://wandb.ai/georgerapeanu/thesis/sweeps/pj49gpx4\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project = 'thesis')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:27:41.518595490Z",
     "start_time": "2024-02-15T14:27:38.289982702Z"
    }
   },
   "id": "dcaa70e2811a34b0",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: wwcspg7b with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tboard_embedding_size: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tboard_intermediary_channels: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tcontext_length: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tconv_modules_count: 4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tff_inner_channels: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlr: 0.10686326782814902\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tmodel_name: model\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_epochs: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_heads: 8\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: sgd\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tpast_boards: 0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tpredict_sentences: 10\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tsamples_per_train_epoch: 100000\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tsp_vocab: 900\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tstride_big_sequences: 256\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \ttext_embedding_size: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \ttransformer_blocks: 4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mgeorgerapeanu\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/georgerapeanu/Desktop/thesis/wandb/run-20240215_162743-wwcspg7b</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/georgerapeanu/thesis/runs/wwcspg7b' target=\"_blank\">wandering-sweep-1</a></strong> to <a href='https://wandb.ai/georgerapeanu/thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/georgerapeanu/thesis/sweeps/pj49gpx4' target=\"_blank\">https://wandb.ai/georgerapeanu/thesis/sweeps/pj49gpx4</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/georgerapeanu/thesis' target=\"_blank\">https://wandb.ai/georgerapeanu/thesis</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/georgerapeanu/thesis/sweeps/pj49gpx4' target=\"_blank\">https://wandb.ai/georgerapeanu/thesis/sweeps/pj49gpx4</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/georgerapeanu/thesis/runs/wwcspg7b' target=\"_blank\">https://wandb.ai/georgerapeanu/thesis/runs/wwcspg7b</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=run)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-15T14:27:41.522093762Z"
    }
   },
   "id": "2a7a019ea39610e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "79fd132c06e5dfbd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "90830bdd67274a3d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
